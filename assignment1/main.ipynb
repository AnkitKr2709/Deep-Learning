{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Dse9_EWeG7Um"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-15 18:25:30.027977: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-10-15 18:25:30.028030: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-10-15 18:25:30.028086: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-10-15 18:25:30.039094: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/media/G/Codes/repos/Deep-Learning/venv_dl/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2023-10-15 18:25:43.542622: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
            "2023-10-15 18:25:43.542706: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: vm1.libvirt\n",
            "2023-10-15 18:25:43.542728: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: vm1.libvirt\n",
            "2023-10-15 18:25:43.542872: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 525.125.6\n",
            "2023-10-15 18:25:43.542938: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 525.125.6\n",
            "2023-10-15 18:25:43.542955: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 525.125.6\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "import cv2\n",
        "\n",
        "\n",
        "data = tfds.load('tf_flowers')\n",
        "tf.config.list_physical_devices()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouWLsOP8H4LF"
      },
      "source": [
        "## SRCNN and FSRCNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVlI-2EZHahm"
      },
      "outputs": [],
      "source": [
        "train_data = data['train'].skip(600)\n",
        "test_data = data['train'].take(600)\n",
        "\n",
        "@tf.function\n",
        "def build_data(data):\n",
        "  cropped = tf.dtypes.cast(tf.image.random_crop(data['image'] / 255, (128, 128, 3)), tf.float32)\n",
        "  lr = tf.image.resize(cropped, (64, 64))\n",
        "  lr = tf.image.resize(lr, (128, 128), method = tf.image.ResizeMethod.BICUBIC)\n",
        "  return (lr, cropped)\n",
        "\n",
        "def downsample_image(image,scale):\n",
        "  lr = tf.image.resize(image / 255, (image.shape[0]//scale, image.shape[1]//scale))\n",
        "  lr = tf.image.resize(lr, (image.shape[0], image.shape[1]), method = tf.image.ResizeMethod.BICUBIC)\n",
        "  return lr\n",
        "\n",
        "def upsample_image(image,scale):\n",
        "  hr = tf.image.resize(image / 255, (image.shape[0] * scale, image.shape[1] * scale), method=tf.image.ResizeMethod.BICUBIC)\n",
        "  hr = tf.image.resize(hr, (128, 128), method=tf.image.ResizeMethod.BICUBIC)\n",
        "  return hr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i37gD1EeHbfi"
      },
      "outputs": [],
      "source": [
        "train_dataset_mapped = train_data.map(build_data, num_parallel_calls = tf.data.AUTOTUNE)\n",
        "def show_image():\n",
        "    for x in train_dataset_mapped.take(1):\n",
        "      plt.imshow(x[0].numpy())\n",
        "      plt.show()\n",
        "      plt.imshow(x[1].numpy())\n",
        "      plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VS4I3tGRHeP2"
      },
      "outputs": [],
      "source": [
        "SRCNN_915=tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64,9,padding='same',activation='relu'),\n",
        "    tf.keras.layers.Conv2D(64,1,padding='same',activation='relu'),\n",
        "    tf.keras.layers.Conv2D(3,5,padding='same',activation='relu')\n",
        "])\n",
        "def pixel_mse_loss(y_true,y_pred):\n",
        "  return tf.reduce_mean( (y_true - y_pred) ** 2 )\n",
        "\n",
        "def PSNR(y_true,y_pred):\n",
        "  mse = tf.reduce_mean( (y_true - y_pred) ** 2 )\n",
        "  return 20 * log10(1 / (mse ** 0.5))\n",
        "\n",
        "def log10(x):\n",
        "  numerator = tf.log(x)\n",
        "  denominator = tf.log(tf.constant(10, dtype=numerator.dtype))\n",
        "  return numerator / denominator\n",
        "\n",
        "SRCNN_915.compile(optimizer = tf.keras.optimizers.Adam(0.001), loss = pixel_mse_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQn897ByHiXG"
      },
      "outputs": [],
      "source": [
        "total_iterations = 20\n",
        "for iteration in range(total_iterations):\n",
        "    print(f\"Iteration: {iteration + 1} / {total_iterations}\")\n",
        "    train_dataset_mapped = train_data.map(build_data, num_parallel_calls = tf.data.AUTOTUNE).batch(128)\n",
        "    val_dataset_mapped = test_data.map(build_data, num_parallel_calls = tf.data.AUTOTUNE).batch(128)\n",
        "    SRCNN_915.fit(train_dataset_mapped, epochs = 1,validation_data = val_dataset_mapped)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "If3ThOfEHk9p"
      },
      "outputs": [],
      "source": [
        "train_dataset_mapped = train_data.map(build_data,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "for x in train_data.take(2):\n",
        "  fig = plt.figure(figsize=(12,4))\n",
        "\n",
        "  plt.subplot(1,3,1)\n",
        "  plt.imshow(x['image'].numpy())\n",
        "  plt.axis('off')\n",
        "  plt.subplot(1,3,2)\n",
        "  lr = downsample_image(x['image'].numpy(),4)\n",
        "  plt.imshow(lr.numpy())\n",
        "  plt.axis('off')\n",
        "  plt.subplot(1,3,3)\n",
        "  pred = SRCNN_915(np.array([lr]))\n",
        "  plt.imshow(pred[0].numpy())\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-qn-dkBHoAq"
      },
      "outputs": [],
      "source": [
        "FSRCNN = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, 9, padding = 'same', activation = 'relu'),\n",
        "    tf.keras.layers.Conv2D(64, 1, padding = 'same', activation = 'relu'),\n",
        "    tf.keras.layers.Conv2D(3, 5, padding = 'same', activation = 'relu'),\n",
        "    tf.keras.layers.Conv2DTranspose(3, 3, padding = 'same', activation = 'relu')\n",
        "])\n",
        "\n",
        "FSRCNN.compile(optimizer=tf.keras.optimizers.Adam(0.001),loss=pixel_mse_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWs5Rd4IHrQF"
      },
      "outputs": [],
      "source": [
        "total_iterations = 20\n",
        "train_data = data['train'].skip(600)\n",
        "test_data = data['train'].take(600)\n",
        "train_dataset_mapped = train_data.map(build_data, num_parallel_calls = tf.data.AUTOTUNE)\n",
        "for iteration in range(total_iterations):\n",
        "    print(f\"Iteration: {iteration + 1} / {total_iterations}\")\n",
        "    train_dataset_mapped = train_data.map(build_data, num_parallel_calls = tf.data.AUTOTUNE).batch(128)\n",
        "    val_dataset_mapped = test_data.map(build_data, num_parallel_calls = tf.data.AUTOTUNE).batch(128)\n",
        "    FSRCNN.fit(train_dataset_mapped, epochs = 1,validation_data = val_dataset_mapped)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rjcu3L2iHujj"
      },
      "outputs": [],
      "source": [
        "train_dataset_mapped = train_data.map(build_data,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "for x in train_data.take(2):\n",
        "  fig = plt.figure(figsize=(12,4))\n",
        "  plt.subplot(1,3,1)\n",
        "  plt.imshow(x['image'].numpy())\n",
        "  plt.axis('off')\n",
        "  plt.subplot(1,3,2)\n",
        "  lr = downsample_image(x['image'].numpy(),4)\n",
        "  plt.imshow(lr.numpy())\n",
        "  plt.axis('off')\n",
        "  plt.subplot(1,3,3)\n",
        "  pred = FSRCNN(np.array([lr]))\n",
        "  plt.imshow(pred[0].numpy())\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZ4LyLmLIGda"
      },
      "source": [
        "## SRGAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlH37f2jIWCp"
      },
      "source": [
        "# extracting umages from dataset 'tf_flowers'; total 600 images extracted\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaUCAH3QHzFZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import os\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "data, info = tfds.load(\"tf_flowers\", with_info=True)\n",
        "\n",
        "target_dir = \"/content/gdrive/MyDrive/DL_Project/fl_dt\"\n",
        "\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "dataset_list = list(data[\"train\"].as_numpy_iterator())\n",
        "random.shuffle(dataset_list)\n",
        "\n",
        "\n",
        "images_extracted = 0\n",
        "\n",
        "num_images_to_save = 600\n",
        "\n",
        "\n",
        "for example in dataset_list:\n",
        "    image = example[\"image\"]\n",
        "    label = example[\"label\"]\n",
        "    class_name = info.features[\"label\"].int2str(label)\n",
        "\n",
        "\n",
        "    image_filename = f\"{class_name}_{label}_{hash(image.tobytes()):016x}.jpg\"\n",
        "    target_path = os.path.join(target_dir, image_filename)\n",
        "\n",
        "\n",
        "    image_pil = Image.fromarray(image)\n",
        "    image_pil.save(target_path)\n",
        "\n",
        "\n",
        "    images_extracted += 1\n",
        "\n",
        "\n",
        "    if images_extracted >= num_images_to_save:\n",
        "        break\n",
        "\n",
        "print(f\"Saved {num_images_to_save} random images from the TF Flowers dataset to {target_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cOykBaaIggQ"
      },
      "outputs": [],
      "source": [
        "train_dir = \"/content/gdrive/MyDrive/DL_Project/fl_dt\"\n",
        "\n",
        "output_hr_dir = os.path.join(train_dir, \"hr_images_1\")\n",
        "output_lr_dir = os.path.join(train_dir, \"lr_images_1\")\n",
        "os.makedirs(output_hr_dir, exist_ok=True)\n",
        "os.makedirs(output_lr_dir, exist_ok=True)\n",
        "\n",
        "for img_filename in os.listdir(train_dir):\n",
        "    img_path = os.path.join(train_dir, img_filename)\n",
        "    img_array = cv2.imread(img_path)\n",
        "\n",
        "    if img_array is not None and img_array.shape[0] > 0 and img_array.shape[1] > 0:\n",
        "        print(f\"Processing: {img_filename} - Original Shape: {img_array.shape}\")\n",
        "        img_array_hr = cv2.resize(img_array, (128, 128))\n",
        "        img_array_lr = cv2.resize(img_array, (32, 32))\n",
        "        cv2.imwrite(os.path.join(output_hr_dir, img_filename), img_array_hr)\n",
        "        cv2.imwrite(os.path.join(output_lr_dir, img_filename), img_array_lr)\n",
        "        print(f\"Processed: {img_filename} - HR Shape: {img_array_hr.shape}, LR Shape: {img_array_lr.shape}\")\n",
        "    else:\n",
        "        print(f\"Error processing image: {img_filename}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMCIxNUCIpyv"
      },
      "outputs": [],
      "source": [
        "\n",
        "def res_block(ip):\n",
        "\n",
        "    res_model = Conv2D(64, (3,3), padding = \"same\")(ip)\n",
        "    res_model = BatchNormalization(momentum = 0.5)(res_model)\n",
        "    res_model = PReLU(shared_axes = [1,2])(res_model)\n",
        "\n",
        "    res_model = Conv2D(64, (3,3), padding = \"same\")(res_model)\n",
        "    res_model = BatchNormalization(momentum = 0.5)(res_model)\n",
        "\n",
        "    return add([ip,res_model])\n",
        "\n",
        "def upscale_block(ip):\n",
        "\n",
        "    up_model = Conv2D(256, (3,3), padding=\"same\")(ip)\n",
        "    up_model = UpSampling2D( size = 2 )(up_model)\n",
        "    up_model = PReLU(shared_axes=[1,2])(up_model)\n",
        "\n",
        "    return up_model\n",
        "\n",
        "\n",
        "def create_gen(gen_ip, num_res_block):\n",
        "    layers = Conv2D(64, (9,9), padding=\"same\")(gen_ip)\n",
        "    layers = PReLU(shared_axes=[1,2])(layers)\n",
        "\n",
        "    temp = layers\n",
        "\n",
        "    for i in range(num_res_block):\n",
        "        layers = res_block(layers)\n",
        "\n",
        "    layers = Conv2D(64, (3,3), padding=\"same\")(layers)\n",
        "    layers = BatchNormalization(momentum=0.5)(layers)\n",
        "    layers = add([layers,temp])\n",
        "\n",
        "    layers = upscale_block(layers)\n",
        "    layers = upscale_block(layers)\n",
        "\n",
        "    op = Conv2D(3, (9,9), padding=\"same\")(layers)\n",
        "\n",
        "    return Model(inputs=gen_ip, outputs=op)\n",
        "\n",
        "\n",
        "def discriminator_block(ip, filters, strides=1, bn=True):\n",
        "\n",
        "    disc_model = Conv2D(filters, (3,3), strides = strides, padding=\"same\")(ip)\n",
        "\n",
        "    if bn:\n",
        "        disc_model = BatchNormalization( momentum=0.8 )(disc_model)\n",
        "\n",
        "    disc_model = LeakyReLU( alpha=0.2 )(disc_model)\n",
        "\n",
        "    return disc_model\n",
        "\n",
        "\n",
        "\n",
        "def create_disc(disc_ip):\n",
        "\n",
        "    df = 64\n",
        "\n",
        "    d1 = discriminator_block(disc_ip, df, bn=False)\n",
        "    d2 = discriminator_block(d1, df, strides=2)\n",
        "    d3 = discriminator_block(d2, df*2)\n",
        "    d4 = discriminator_block(d3, df*2, strides=2)\n",
        "    d5 = discriminator_block(d4, df*4)\n",
        "    d6 = discriminator_block(d5, df*4, strides=2)\n",
        "    d7 = discriminator_block(d6, df*8)\n",
        "    d8 = discriminator_block(d7, df*8, strides=2)\n",
        "\n",
        "    d8_5 = Flatten()(d8)\n",
        "    d9 = Dense(df*16)(d8_5)\n",
        "    d10 = LeakyReLU(alpha=0.2)(d9)\n",
        "    validity = Dense(1, activation='sigmoid')(d10)\n",
        "\n",
        "    return Model(disc_ip, validity)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXuUnoI-JBXR"
      },
      "outputs": [],
      "source": [
        "from keras.applications import VGG19\n",
        "\n",
        "def build_vgg(hr_shape):\n",
        "\n",
        "    vgg = VGG19(weights=\"imagenet\",include_top=False, input_shape=hr_shape)\n",
        "\n",
        "    return Model(inputs=vgg.inputs, outputs=vgg.layers[10].output)\n",
        "\n",
        "\n",
        "def create_comb(gen_model, disc_model, vgg, lr_ip, hr_ip):\n",
        "    gen_img = gen_model(lr_ip)\n",
        "\n",
        "    gen_features = vgg(gen_img)\n",
        "\n",
        "    disc_model.trainable = False\n",
        "    validity = disc_model(gen_img)\n",
        "\n",
        "    return Model(inputs=[lr_ip, hr_ip], outputs=[validity, gen_features])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PXHCjvVJHeE"
      },
      "outputs": [],
      "source": [
        "lr_list = os.listdir(\"/content/gdrive/MyDrive/DL_Project/fl_dt/lr_images_1\")\n",
        "\n",
        "lr_images = []\n",
        "for img in lr_list:\n",
        "    img_lr = cv2.imread(\"/content/gdrive/MyDrive/DL_Project/fl_dt/lr_images_1/\" + img)\n",
        "    if img_lr is not None:\n",
        "        img_lr = cv2.cvtColor(img_lr, cv2.COLOR_BGR2RGB)\n",
        "        lr_images.append(img_lr)\n",
        "\n",
        "hr_list = os.listdir(\"/content/gdrive/MyDrive/DL_Project/fl_dt/hr_images_1\")\n",
        "\n",
        "hr_images = []\n",
        "for img in hr_list:\n",
        "    img_hr = cv2.imread(\"/content/gdrive/MyDrive/DL_Project/fl_dt/hr_images_1/\" + img)\n",
        "    if img_hr is not None:\n",
        "        img_hr = cv2.cvtColor(img_hr, cv2.COLOR_BGR2RGB)\n",
        "        hr_images.append(img_hr)\n",
        "\n",
        "lr_images = np.array(lr_images)\n",
        "hr_images = np.array(hr_images)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maBP3seNJLKB"
      },
      "outputs": [],
      "source": [
        "lr_images = lr_images / 255.\n",
        "hr_images = hr_images / 255.\n",
        "\n",
        "lr_train, lr_test, hr_train, hr_test = train_test_split(lr_images, hr_images,\n",
        "                                                      test_size=0.33, random_state=42)\n",
        "\n",
        "\n",
        "hr_shape = (hr_train.shape[1], hr_train.shape[2], hr_train.shape[3])\n",
        "lr_shape = (lr_train.shape[1], lr_train.shape[2], lr_train.shape[3])\n",
        "\n",
        "lr_ip = Input(shape=lr_shape)\n",
        "hr_ip = Input(shape=hr_shape)\n",
        "\n",
        "generator = create_gen(lr_ip, num_res_block = 16)\n",
        "generator.summary()\n",
        "\n",
        "discriminator = create_disc(hr_ip)\n",
        "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "discriminator.summary()\n",
        "\n",
        "vgg = build_vgg((128,128,3))\n",
        "print(vgg.summary())\n",
        "vgg.trainable = False\n",
        "\n",
        "gan_model = create_comb(generator, discriminator, vgg, lr_ip, hr_ip)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zG229HceJP5I"
      },
      "outputs": [],
      "source": [
        "gan_model.compile(loss=[\"binary_crossentropy\", \"mse\"], loss_weights=[1e-3, 1], optimizer=\"adam\")\n",
        "gan_model.summary()\n",
        "\n",
        "batch_size = 1\n",
        "train_lr_batches = []\n",
        "train_hr_batches = []\n",
        "for it in range(int(hr_train.shape[0] / batch_size)):\n",
        "    start_idx = it * batch_size\n",
        "    end_idx = start_idx + batch_size\n",
        "    train_hr_batches.append(hr_train[start_idx:end_idx])\n",
        "    train_lr_batches.append(lr_train[start_idx:end_idx])\n",
        "\n",
        "\n",
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "\n",
        "    fake_label = np.zeros((batch_size, 1))\n",
        "    real_label = np.ones((batch_size,1))\n",
        "\n",
        "    g_losses = []\n",
        "    d_losses = []\n",
        "\n",
        "\n",
        "    for b in tqdm(range(len(train_hr_batches))):\n",
        "        lr_imgs = train_lr_batches[b]\n",
        "        hr_imgs = train_hr_batches[b]\n",
        "\n",
        "        fake_imgs = generator.predict_on_batch(lr_imgs)\n",
        "\n",
        "\n",
        "        discriminator.trainable = True\n",
        "        d_loss_gen = discriminator.train_on_batch(fake_imgs, fake_label)\n",
        "        d_loss_real = discriminator.train_on_batch(hr_imgs, real_label)\n",
        "\n",
        "\n",
        "        discriminator.trainable = False\n",
        "\n",
        "\n",
        "        d_loss = 0.5 * np.add(d_loss_gen, d_loss_real)\n",
        "\n",
        "\n",
        "        image_features = vgg.predict(hr_imgs)\n",
        "\n",
        "\n",
        "\n",
        "        g_loss, _, _ = gan_model.train_on_batch([lr_imgs, hr_imgs], [real_label, image_features])\n",
        "\n",
        "\n",
        "        d_losses.append(d_loss)\n",
        "        g_losses.append(g_loss)\n",
        "\n",
        "    g_losses = np.array(g_losses)\n",
        "    d_losses = np.array(d_losses)\n",
        "\n",
        "    g_loss = np.sum(g_losses, axis=0) / len(g_losses)\n",
        "    d_loss = np.sum(d_losses, axis=0) / len(d_losses)\n",
        "\n",
        "    print(\"epoch:\", e+1 ,\"g_loss:\", g_loss, \"d_loss:\", d_loss)\n",
        "\n",
        "    generator.save(\"/content/gdrive/MyDrive/DL_Project/gen_e.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQF_i772JTZN"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "from numpy.random import randint\n",
        "\n",
        "generator = load_model('/content/gdrive/MyDrive/DL_Project/gen_e.h5', compile=False)\n",
        "\n",
        "\n",
        "[X1, X2] = [lr_test, hr_test]\n",
        "ix = randint(0, len(X1), 1)\n",
        "src_image, tar_image = X1[ix], X2[ix]\n",
        "\n",
        "gen_image = generator.predict(src_image)\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(231)\n",
        "plt.title('LR Image')\n",
        "plt.imshow(src_image[0,:,:,:])\n",
        "plt.subplot(232)\n",
        "plt.title('Superresolution')\n",
        "plt.imshow(gen_image[0,:,:,:])\n",
        "plt.subplot(233)\n",
        "plt.title('Orig. HR image')\n",
        "plt.imshow(tar_image[0,:,:,:])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INzXXjHIJYKi"
      },
      "outputs": [],
      "source": [
        "sreeni_lr = cv2.imread(\"/content/gdrive/MyDrive/DL_Project/fl_dt/lr_images_1/daisy_1_-10790155265df092.jpg\")\n",
        "sreeni_hr = cv2.imread(\"/content/gdrive/MyDrive/DL_Project/fl_dt/hr_images_1/daisy_1_-10790155265df092.jpg\")\n",
        "\n",
        "\n",
        "sreeni_lr = cv2.cvtColor(sreeni_lr, cv2.COLOR_BGR2RGB)\n",
        "sreeni_hr = cv2.cvtColor(sreeni_hr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "sreeni_lr = sreeni_lr / 255.\n",
        "sreeni_hr = sreeni_hr / 255.\n",
        "\n",
        "sreeni_lr = np.expand_dims(sreeni_lr, axis=0)\n",
        "sreeni_hr = np.expand_dims(sreeni_hr, axis=0)\n",
        "\n",
        "generated_sreeni_hr = generator.predict(sreeni_lr)\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(231)\n",
        "plt.title('LR Image')\n",
        "plt.imshow(sreeni_lr[0,:,:,:])\n",
        "plt.subplot(232)\n",
        "plt.title('Superresolution')\n",
        "plt.imshow(generated_sreeni_hr[0,:,:,:])\n",
        "plt.subplot(233)\n",
        "plt.title('Orig. HR image')\n",
        "plt.imshow(sreeni_hr[0,:,:,:])\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
